{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Voice Codex — Exploratory Analysis\n",
    "\n",
    "This notebook walks through:\n",
    "1. Loading a pre-built feature archive (`features.npz`)\n",
    "2. Sanity-checking with `verify.py`\n",
    "3. Descriptive statistics\n",
    "4. Correlation heatmap\n",
    "5. PCA projection\n",
    "6. F0 and MFCC distribution plots\n",
    "\n",
    "Run `aggregate.py` first to generate `features.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from aggregate import load_npz\n",
    "from verify import verify\n",
    "from extract import N_MFCC\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPZ_PATH = Path('features.npz')  # adjust if needed\n",
    "\n",
    "if not NPZ_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f'{NPZ_PATH} not found.\\n'\n",
    "        'Run:  python aggregate.py <audio_dir> --output features.npz'\n",
    "    )\n",
    "\n",
    "features, files = load_npz(NPZ_PATH)\n",
    "print(f'Loaded {features.shape[0]} samples × {features.shape[1]} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = verify(features, files=files)\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a labelled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALAR_NAMES = [\n",
    "    'f0_mean', 'f0_std', 'f0_min', 'f0_max', 'f0_voiced_frac',\n",
    "    'hnr_mean', 'rms_mean', 'rms_std',\n",
    "    'centroid_mean', 'centroid_std', 'bandwidth_mean', 'rolloff_mean', 'zcr_mean',\n",
    "]\n",
    "mfcc_mean_names  = [f'mfcc_mean_{i}'  for i in range(N_MFCC)]\n",
    "mfcc_std_names   = [f'mfcc_std_{i}'   for i in range(N_MFCC)]\n",
    "delta_mean_names = [f'dmfcc_mean_{i}' for i in range(N_MFCC)]\n",
    "delta_std_names  = [f'dmfcc_std_{i}'  for i in range(N_MFCC)]\n",
    "\n",
    "all_names = SCALAR_NAMES + mfcc_mean_names + mfcc_std_names + delta_mean_names + delta_std_names\n",
    "\n",
    "df = pd.DataFrame(features, columns=all_names)\n",
    "df.insert(0, 'file', [Path(f).name for f in files])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[SCALAR_NAMES].describe().T.style.background_gradient(cmap='YlOrRd', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation heatmap (scalar features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[SCALAR_NAMES].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr, mask=mask, annot=True, fmt='.2f',\n",
    "    cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "    linewidths=0.5, ax=ax\n",
    ")\n",
    "ax.set_title('Feature Correlation (scalar features)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. F0 distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "f0_nonzero = df['f0_mean'][df['f0_mean'] > 0]\n",
    "sns.histplot(f0_nonzero, bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_xlabel('F0 mean (Hz)')\n",
    "axes[0].set_title('F0 Mean Distribution')\n",
    "\n",
    "sns.histplot(df['f0_voiced_frac'], bins=20, kde=True, ax=axes[1])\n",
    "axes[1].set_xlabel('Voiced fraction')\n",
    "axes[1].set_title('Voiced Frame Fraction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MFCC mean profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_data = df[mfcc_mean_names].values   # (N, 13)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.fill_between(\n",
    "    range(N_MFCC),\n",
    "    mfcc_data.mean(0) - mfcc_data.std(0),\n",
    "    mfcc_data.mean(0) + mfcc_data.std(0),\n",
    "    alpha=0.3, label='±1 std'\n",
    ")\n",
    "ax.plot(range(N_MFCC), mfcc_data.mean(0), marker='o', label='mean')\n",
    "ax.set_xticks(range(N_MFCC))\n",
    "ax.set_xticklabels([f'C{i}' for i in range(N_MFCC)])\n",
    "ax.set_xlabel('MFCC coefficient')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('MFCC Mean Profile (corpus average ± std)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. PCA — 2D projection of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [c for c in df.columns if c != 'file']\n",
    "X = df[numeric_cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=min(10, X_scaled.shape[1]))\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Explained variance\n",
    "axes[0].bar(range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "            np.cumsum(pca.explained_variance_ratio_) * 100)\n",
    "axes[0].axhline(90, color='red', linestyle='--', label='90 %')\n",
    "axes[0].set_xlabel('Components')\n",
    "axes[0].set_ylabel('Cumulative variance explained (%)')\n",
    "axes[0].set_title('PCA — Cumulative Variance')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2-D scatter\n",
    "X2 = pca.transform(X_scaled)[:, :2]\n",
    "axes[1].scatter(X2[:, 0], X2[:, 1], alpha=0.6, edgecolors='k', linewidths=0.3, s=40)\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f} %)')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f} %)')\n",
    "axes[1].set_title('PCA 2-D Projection')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv = 'features_labelled.csv'\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f'Saved {out_csv}  ({df.shape[0]} rows × {df.shape[1]} cols)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
